{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN9EyO9CkfUx4r0SyqmRlpB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"HCv7iHDZJveA","executionInfo":{"status":"ok","timestamp":1708662976052,"user_tz":-540,"elapsed":6299,"user":{"displayName":"Yoshi Sato","userId":"03243410627794638618"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.utils.data import DataLoader\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms"]},{"cell_type":"code","source":["class AlexNet(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","\n","    #Extracts features and responsible for capturing spatial hierarchies in images\n","    self.net = nn.Sequential(\n","        nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4),\n","        nn.ReLU(),\n","        nn.LocalResponseNorm(size=5, alpha=.0001, beta=.75, k=2),\n","        nn.MaxPool2d(3,2),\n","        #Padding for kernels is not explicitly mentioned in the papers\n","        nn.Conv2d(96, 256, 5, padding=2),#Bias=1 (constant)\n","        nn.ReLU(),\n","        nn.LocalResponseNorm(5, .0001, .75, 2),\n","        nn.MaxPool2d(3,2),\n","        nn.Conv2d(256, 384, 3, padding=1),\n","        nn.ReLU(),\n","        nn.Conv2d(384, 384, 3, padding=1),#Bias=1 (constant)\n","        nn.ReLU(),\n","        nn.Conv2d(384, 256, 3, padding=1),#Bias=1 (constant)\n","        nn.ReLU(),\n","        nn.MaxPool2d(3,2)\n","    )\n","    #Fully-connected (dense) layers that perform the actual classifications, takes the high-level features extracted by conv layers and uses them to classify images into different categories\n","    self.classifier = nn.Sequential(\n","        nn.Linear(6*6*256, 4096),\n","        nn.ReLU(),\n","        nn.Dropout(p=0.5), #During forward-prop, wieghts are set to zero, then during back-prop, the removed weights demonstrate zeroed gradients\n","        nn.Linear(4096, 4096),\n","        nn.ReLU(),\n","        nn.Dropout(p=0.5),\n","        nn.Linear(4096, 1000),\n","    )\n","    self.init_weight_bias() #initialize bias\n","\n","\n","  def init_weight_bias(self):\n","    for module in self.modules:\n","      if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n","        nn.init.normal_(module.weight, mean=0, std=0.01)\n","        nn.init.constant_(module.bias, 0)\n","\n","    #To ensure that the ReLU activation receives positive inputs, helping the learning process to start more efficiently\n","    nn.init.constant_(self.net[4].bias, 1)\n","    nn.init.constant_(self.net[10].bias, 1)\n","    nn.init.constant_(self.net[13].bias, 1)\n","    nn.init.constant_(self.classifier[0].bias, 1)\n","    nn.init.constant_(self.classifier[3].bias, 1)\n","    nn.init.constant_(self.classifier[6].bias, 1)\n","\n","  def forward(self, x):\n","    x = self.net(x)\n","    x = torch.flatten(x,1)\n","    x = self.classifier(x)\n","    return x\n","\n"],"metadata":{"id":"zCUDaRA9NHGB","executionInfo":{"status":"ok","timestamp":1708670675985,"user_tz":-540,"elapsed":278,"user":{"displayName":"Yoshi Sato","userId":"03243410627794638618"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class Net(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.conv1 = nn.Conv2d(3, 96, 11, stride=4)\n","    self.pool = nn.MaxPool2d(3, 2)\n","    self.lrn = nn.LocalResponseNorm(size=5, alpha=.0001, beta=.75, k=2)\n","    self.conv2 = nn.Conv2d(96, 256, 5, padding=2)\n","    self.conv3 = nn.Conv2d(256, 384, 3, padding=1)\n","    self.conv4 = nn.Conv2d(384, 384, 3, padding=1)\n","    self.conv5 = nn.Conv2d(384, 256, 3, padding=1)\n","\n","    self.fc1 = nn.Linear(6*6*256, 4096)\n","    self.dropout = nn.Dropout(p=0.5)\n","    self.fc2 = nn.Linear(4096, 4096)\n","    self.fc3 = nn.Linear(4096, 1000)\n","\n","    self.init_weight_bias()\n","\n","  def init_weight_bias(self):\n","    for module in self.modules():\n","        if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n","            nn.init.normal_(module.weight, mean=0.0, std=0.01)\n","            nn.init.constant_(module.bias, 0)\n","\n","    nn.init.constant_(self.conv2.bias, 1)\n","    nn.init.constant_(self.conv4.bias, 1)\n","    nn.init.constant_(self.conv5.bias, 1)\n","    nn.init.constant_(self.fc1.bias, 1)\n","    nn.init.constant_(self.fc2.bias, 1)\n","    nn.init.constant_(self.fc3.bias, 1)\n","\n","  def forward(self, x):\n","    x = self.pool(self.lrn(F.relu(self.conv1(x)))) #LRN (local response normalization) on ReLU output, then maxpool\n","    x = self.pool(self.lrn(F.relu(self.conv2(x))))\n","    x = F.relu(self.conv3(x))\n","    x = F.relu(self.conv4(x))\n","    x = self.pool(F.relu(self.conv5(x)))\n","    x = torch.flatten(x,1)\n","    x = self.dropout(F.relu(self.fc1(x))) #Dropout in the first two fully-connected layers,  without dropout network exhibits substantial overfitting, but doubles number of iterations to converge\n","    x = self.dropout(F.relu(self.fc2(x)))\n","    x = self.fc3(x)\n","    return x\n","\n","net = Net()"],"metadata":{"id":"ZlGycV1lMxBe","executionInfo":{"status":"ok","timestamp":1708670678890,"user_tz":-540,"elapsed":1335,"user":{"displayName":"Yoshi Sato","userId":"03243410627794638618"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7llCswJCM_kR"},"execution_count":null,"outputs":[]}]}